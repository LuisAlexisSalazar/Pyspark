{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "eb0b208d-191f-460e-9f4f-d2b658f2f4ed",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Laboratorio Ventas Ecommers\n",
    "1. Construyendo streaming DataFrames\n",
    "1. Mostrando consultas streaming\n",
    "1. Escribiendo resultados streaming \n",
    "1. Monitoreando consultas streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\LibreriasPython\\\\spark-3.1.2-bin-hadoop2.7\\\\python\\\\pyspark'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only when is Local\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('ManagementStream').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8a00ec88-664a-4ebe-9fdf-a7dfefdfbe62",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = \"device STRING, ecommerce STRUCT<purchase_revenue_in_usd: DOUBLE, total_item_quantity: BIGINT, unique_items: BIGINT>, event_name STRING, event_previous_timestamp BIGINT, event_timestamp BIGINT, geo STRUCT<city: STRING, state: STRING>, items ARRAY<STRUCT<coupon: STRING, item_id: STRING, item_name: STRING, item_revenue_in_usd: DOUBLE, price_in_usd: DOUBLE, quantity: BIGINT>>, traffic_source STRING, user_first_touch_timestamp BIGINT, user_id STRING\"\n",
    "\n",
    "eventsPath = \"../data/events.parquet\" # path to events\n",
    "\n",
    "\n",
    "dfStream = (spark.readStream\n",
    "  .schema(schema)\n",
    "  .option(\"maxFilesPerTrigger\", 1)\n",
    "  .parquet(eventsPath)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f1baf64d-3b61-4bc4-b67d-14675b8330d0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Construyendo streaming DataFrames\n",
    "\n",
    "- Valide que el DataFrame se procesa en Streaming 'isStreaming'\n",
    "\n",
    "- Genere emailTrafficDF a partir de:\n",
    "  - Filtrando df según  (traffic_source == 'email') \n",
    "  - Use método withColumn generando la columna \"mobile\" cuya lógica es col(\"device\").isin([\"iOS\", \"Android\"])\n",
    "  - Seleccione \"user_id\", \"event_timestamp\", \"mobile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validar si procesamiento es streaming\n",
    "dfStream.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma en STREAMING\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "dfStreamFilter = (dfStream.filter(F.col('traffic_source')== F.lit('email')).withColumn('mobile',F.col(\"device\").isin([\"iOS\", \"Android\"])).select(\"user_id\", \"event_timestamp\", \"mobile\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6e3adaeb-ccfc-4de5-a7a9-1ca10c3b2165",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Mostrando consultas streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a8f6f383-2d94-4f45-b558-cdb997888965",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "userhome = \"../data\"\n",
    "checkpointPath = userhome + \"/email_traffic/checkpoint\"\n",
    "outputPath = userhome + \"/email_traffic/output\"\n",
    "\n",
    "devicesQuery = (dfStream.writeStream\n",
    "  .outputMode(\"append\")\n",
    "  .format(\"parquet\")\n",
    "  .queryName(\"email_traffic_p\")\n",
    "  .trigger(processingTime=\"1 second\")\n",
    "  .option(\"checkpointLocation\", checkpointPath)\n",
    "  .start(outputPath)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b00c2a08-68f0-4268-9df9-3e53868f2b66",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Monitoreando consultas Streaming\n",
    "\n",
    "- Muestre 'id' de streaming\n",
    "- Muestre status de streaming\n",
    "- Pare ejecución streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8770eb4b-5256-491d-a8ed-ac227ccbe506",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e68f6c15-3a7c-413f-935a-e2a6b12d239a'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ID\n",
    "devicesQuery.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a50d1751-379c-49bd-b2e3-a85ede96c0fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': \"Terminated with exception: Option 'basePath' must be a directory\",\n",
       " 'isDataAvailable': False,\n",
       " 'isTriggerActive': False}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# status\n",
    "devicesQuery.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "787f368f-8f15-4a5e-b65b-c6e8398f42b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method StreamingQuery.stop of <pyspark.sql.streaming.StreamingQuery object at 0x000002C4C7591BE0>>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stop\n",
    "devicesQuery.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e68f6c15-3a7c-413f-935a-e2a6b12d239a'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devicesQuery.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Unable to infer schema for Parquet at . It must be specified manually",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16048/2406117482.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_parquet_describe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# df_parquet_describe().show()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\LibreriasPython\\spark-3.1.2-bin-hadoop2.7\\python\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[1;34m(self, *paths, **options)\u001b[0m\n\u001b[0;32m    456\u001b[0m                        modifiedAfter=modifiedAfter)\n\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     def text(self, paths, wholetext=False, lineSep=None, pathGlobFilter=None,\n",
      "\u001b[1;32mE:\\LibreriasPython\\spark-3.1.2-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\LibreriasPython\\spark-3.1.2-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: Unable to infer schema for Parquet at . It must be specified manually"
     ]
    }
   ],
   "source": [
    "df_parquet_describe = spark.read.parquet(outputPath)\n",
    "# df_parquet_describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9a3f6cbc-6905-4401-955b-7072e6513171",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Laboratorio de ventas de cupones\n",
    "\n",
    "Procese y agregue datos de transmisión en transacciones usando cupones.\n",
    "\n",
    "1. Leer flujo de datos\n",
    "1. Filtrar por transacciones con códigos de cupones\n",
    "1. Escribir resultados de consultas de transmisión en parquet\n",
    "1. Supervisar la consulta de transmisión\n",
    "1. Detener consulta de transmisión\n",
    "\n",
    "##### Classes\n",
    "- [DataStreamReader](http://spark.apache.org/docs/3.0.0/api/scala/org/apache/spark/sql/streaming/DataStreamReader.html)\n",
    "- [DataStreamWriter](http://spark.apache.org/docs/3.0.0/api/scala/org/apache/spark/sql/streaming/DataStreamWriter.html)\n",
    "- [StreamingQuery](http://spark.apache.org/docs/3.0.0/api/scala/org/apache/spark/sql/streaming/StreamingQuery.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e1abfc51-47c2-4721-ba7f-bb78a5ea0e79",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = \"order_id BIGINT, email STRING, transaction_timestamp BIGINT, total_item_quantity BIGINT, purchase_revenue_in_usd DOUBLE, unique_items BIGINT, items ARRAY<STRUCT<coupon: STRING, item_id: STRING, item_name: STRING, item_revenue_in_usd: DOUBLE, price_in_usd: DOUBLE, quantity: BIGINT>>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d6675491-ed5a-4bad-b74b-f7cb2fe5167d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Lectura de Datos Streaming\n",
    "- Genere el schema correspondiente **`schema`**\n",
    "- Setea el proceso para la lectura de 1 fila por trigger\n",
    "- Lea a partir de archivo parquet almanenado en **`salesPath`**\n",
    "\n",
    "Assign the resulting DataFrame to **`df`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4e39a733-74e6-4fc9-b829-abca41c9f01b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "salesPath = '' # path\n",
    "\n",
    "df = (spark.FILL_IN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3bd5d8cd-4653-4884-bc5d-fc2a7783021e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "-sandbox\n",
    "##### <img alt=\"Best Practice\" title=\"Best Practice\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-blue-ribbon.svg\"/> Check your work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5961eb62-bd16-46f9-a557-c81c3fe8beb0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assert df.isStreaming\n",
    "assert df.columns == ['order_id', 'email', 'transaction_timestamp', 'total_item_quantity', 'purchase_revenue_in_usd', 'unique_items', 'items']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "26193ef4-0234-4327-91ca-965d7e0702a5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Filtrado por Transacción\n",
    "- Explotar campo  **`items`**  en **`df`**\n",
    "- Filre cada uno de los archivos donde **`items.coupon`** es no nulo\n",
    "\n",
    "Asigne el Dataframe como resultado **`couponSalesDF`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8f57577a-d6b6-459c-9e28-02b7afae504e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "couponSalesDF = (df.FILL_IN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "636641b8-8f19-49d2-80bb-27e65d4b12fd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "-sandbox\n",
    "##### <img alt=\"Best Practice\" title=\"Best Practice\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-blue-ribbon.svg\"/> Check your work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e7bcd6f9-7796-4fe6-a4de-57eaca850c54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schemaStr = str(couponSalesDF.schema)\n",
    "assert \"StructField(items,StructType(List(StructField(coupon\" in schemaStr, \"items column was not exploded\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e275f571-ea02-4ebf-af97-bb1820c7b275",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Escriba consulta Streaming en archivo parquet\n",
    "- Configure la consulta de estreaming a modo \"append\"\n",
    "- Asigne el nombre de \"coupon_sales\" a la consulta\n",
    "- Setee el intervalo de guardado a 1 segundo\n",
    "- Setee la localizaciòn del checkpoint a **`couponsCheckpointPath`**\n",
    "- Coloque el output path a **`couponsOutputPath`**\n",
    "\n",
    "Asigne el resultado del streaming a **`couponSalesQuery`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b41b41df-5777-44ae-b30d-ca75e6347e68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "couponsCheckpointPath = workingDir + \"/coupon-sales/checkpoint\"\n",
    "couponsOutputPath = workingDir + \"/coupon-sales/output\"\n",
    "\n",
    "couponSalesQuery = (couponSalesDF.FILL_IN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f87a623a-2b0a-462f-9df6-f957cf7f15f2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "-sandbox\n",
    "##### <img alt=\"Best Practice\" title=\"Best Practice\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-blue-ribbon.svg\"/> Check your work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2872d9db-e8c2-4219-a482-c3222f491364",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "untilStreamIsReady(\"coupon_sales\")\n",
    "assert couponSalesQuery.isActive\n",
    "assert len(dbutils.fs.ls(couponsOutputPath)) > 0\n",
    "assert len(dbutils.fs.ls(couponsCheckpointPath)) > 0\n",
    "assert \"coupon_sales\" in couponSalesQuery.lastProgress[\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "59a1e298-9178-4073-a1cd-68ff8afd1840",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. Monitoree consulta streaming\n",
    "- Obtenga ID de consulta streaming\n",
    "- Obtenga el status del streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d2e0e069-0cf9-433d-a978-a757ca805709",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "queryID = couponSalesQuery.FILL_IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "67a257a9-8343-438e-b738-3832f9b3e670",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "queryStatus = couponSalesQuery.FILL_IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "22aa79cf-6a60-44a9-991e-cd305e851e5c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "-sandbox\n",
    "##### <img alt=\"Best Practice\" title=\"Best Practice\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-blue-ribbon.svg\"/> Check your work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "aa90d774-1eee-4553-887f-16e560d9f9a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assert type(queryID) == str\n",
    "assert list(queryStatus.keys()) == ['message', 'isDataAvailable', 'isTriggerActive']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fe231027-31f8-472a-a835-1c7b26215902",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5. Pare la ejecuciòn streaming\n",
    "- Pare ejecuciòn streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "29663290-5a24-464e-80ca-4cfd1c0d7ec6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "couponSalesQuery.FILL_IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "86e87fb9-c37a-4259-977c-37b82fe555da",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "-sandbox\n",
    "##### <img alt=\"Best Practice\" title=\"Best Practice\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-blue-ribbon.svg\"/> Check your work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "68ba3da1-8850-4c57-a764-5e41f160ac5d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assert not couponSalesQuery.isActive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b1097801-f720-4b5a-9a9b-d0ac4cdd3c9f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 6. Verifique las filas guardadas en archivo parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "dfb2554d-bcc8-4278-9b59-077992c28e6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c6275f76-3cd1-4dd0-adcb-3fb562bfcd0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.read.parquet(couponsOutputPath))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Laboratorio Spark Streaming",
   "notebookOrigID": 3539616317455873,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
