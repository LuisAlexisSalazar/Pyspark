{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "GOBurNMyVloc",
    "outputId": "3d89c7dc-799a-4dce-bc03-21f10844a06a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 281.4 MB 32 kB/s \n",
      "\u001b[?25hCollecting py4j\n",
      "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
      "\u001b[K     |████████████████████████████████| 198 kB 36.9 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=428814ec05d0ce1f33e98d6db03dd82b3d923c1ab76434dda49a2e8d5ddb83f3\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
     ]
    }
   ],
   "source": [
    "# # Google Colaboraty\n",
    "!pip install pyspark py4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "H75nJFA-Wn3Q",
    "outputId": "79a5578e-6077-4ee1-ca24-3dff8dffdb91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-22335607-9e5b-42dc-ad26-d8e7a1defbbb\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-22335607-9e5b-42dc-ad26-d8e7a1defbbb\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving airbnb.csv to airbnb.csv\n"
     ]
    }
   ],
   "source": [
    "# Google Colaboraty\n",
    "# Files\n",
    "import io\n",
    "from google.colab import files\n",
    "\n",
    "# Cargando data Google Colab\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\LibreriasPython\\\\spark-3.1.2-bin-hadoop2.7\\\\python\\\\pyspark'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only when is Local\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ewdSJ7kqU_hI"
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('ManagementAirbnb').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrUGcisRU_hL"
   },
   "source": [
    "# Ejercicio - Busqueda de Alojamiento en Airbnb.\n",
    "\n",
    "Supongamos que somos un agente de [Airbnb](http://www.airbnb.com) localizado en Lisboa, y tenemos que atender peticiones de varios clientes. Tenemos un archivo llamado `airbnb.csv` (en la carpeta data) donde tenemos información de todos los alojamientos de Airbnb en Lisboa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "RtUmSEzFU_hM",
    "outputId": "f3cbd7d7-95e5-453f-cd47-db225ef59efd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------------+-----------------+-------+--------------------+------------+--------+-----+\n",
      "|room_id|host_id|room_type      |neighborhood     |reviews|overall_satisfaction|accommodates|bedrooms|price|\n",
      "+-------+-------+---------------+-----------------+-------+--------------------+------------+--------+-----+\n",
      "|6499   |14455  |Entire home/apt|Belém            |8      |5.0                 |2           |1.0     |57.0 |\n",
      "|17031  |66015  |Entire home/apt|Alvalade         |0      |0.0                 |2           |1.0     |46.0 |\n",
      "|25659  |107347 |Entire home/apt|Santa Maria Maior|63     |5.0                 |3           |1.0     |69.0 |\n",
      "|29248  |125768 |Entire home/apt|Santa Maria Maior|225    |4.5                 |4           |1.0     |58.0 |\n",
      "|29396  |126415 |Entire home/apt|Santa Maria Maior|132    |5.0                 |4           |1.0     |67.0 |\n",
      "+-------+-------+---------------+-----------------+-------+--------------------+------------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  ------Cargar Data---------\n",
    "airbnCsvPath = \"data/airbnb.csv\"\n",
    "\n",
    "# Emplear lectura de esquema\n",
    "airbnbDF = (spark.read\n",
    "  .option(\"sep\", \",\")\n",
    "  .option(\"header\", True)\n",
    "  .option(\"inferSchema\", True) \n",
    "  .csv(airbnCsvPath))\n",
    "\n",
    "airbnbDF.show(n=5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zZUNNqlkU_hN",
    "outputId": "577a5fac-9559-4822-f7a4-7a42fa3e0631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------\n",
      " summary              | count                \n",
      " room_id              | 13232                \n",
      " host_id              | 13232                \n",
      " room_type            | 13232                \n",
      " neighborhood         | 13232                \n",
      " reviews              | 13232                \n",
      " overall_satisfaction | 13222                \n",
      " accommodates         | 13232                \n",
      " bedrooms             | 13232                \n",
      " price                | 13232                \n",
      "-RECORD 1------------------------------------\n",
      " summary              | mean                 \n",
      " room_id              | 1.0550814671327086E7 \n",
      " host_id              | 3.616443520435309E7  \n",
      " room_type            | null                 \n",
      " neighborhood         | null                 \n",
      " reviews              | 29.13006348246675    \n",
      " overall_satisfaction | 3.2846770533958556   \n",
      " accommodates         | 3.917775090689238    \n",
      " bedrooms             | 1.5495012091898428   \n",
      " price                | 86.59235187424426    \n",
      "-RECORD 2------------------------------------\n",
      " summary              | stddev               \n",
      " room_id              | 6069884.424194057    \n",
      " host_id              | 3.70697493576734E7   \n",
      " room_type            | null                 \n",
      " neighborhood         | null                 \n",
      " reviews              | 42.802761868916676   \n",
      " overall_satisfaction | 2.123235539445721    \n",
      " accommodates         | 2.2937569807503526   \n",
      " bedrooms             | 1.062820699727275    \n",
      " price                | 135.20892645760608   \n",
      "-RECORD 3------------------------------------\n",
      " summary              | min                  \n",
      " room_id              | 6499                 \n",
      " host_id              | 14455                \n",
      " room_type            | Entire home/apt      \n",
      " neighborhood         | Ajuda                \n",
      " reviews              | 0                    \n",
      " overall_satisfaction | 0.0                  \n",
      " accommodates         | 1                    \n",
      " bedrooms             | 0.0                  \n",
      " price                | 10.0                 \n",
      "-RECORD 4------------------------------------\n",
      " summary              | max                  \n",
      " room_id              | 19400722             \n",
      " host_id              | 135915593            \n",
      " room_type            | Shared room          \n",
      " neighborhood         | São Vicente          \n",
      " reviews              | 438                  \n",
      " overall_satisfaction | 5.0                  \n",
      " accommodates         | 16                   \n",
      " bedrooms             | 10.0                 \n",
      " price                | 7496.0               \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrar información básica de datos, columnas, cantidad, etc\n",
    "airbnbDF.describe().show(vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XM46tZVQU_hO",
    "outputId": "75db5ac7-0541-4e1c-9e46-1281093320aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------------+-----------------+-------+--------------------+------------+--------+------+\n",
      "|room_id|host_id|      room_type|     neighborhood|reviews|overall_satisfaction|accommodates|bedrooms| price|\n",
      "+-------+-------+---------------+-----------------+-------+--------------------+------------+--------+------+\n",
      "|   6499|  14455|Entire home/apt|            Belém|      8|                 5.0|           2|     1.0|  57.0|\n",
      "|  17031|  66015|Entire home/apt|         Alvalade|      0|                 0.0|           2|     1.0|  46.0|\n",
      "|  25659| 107347|Entire home/apt|Santa Maria Maior|     63|                 5.0|           3|     1.0|  69.0|\n",
      "|  29248| 125768|Entire home/apt|Santa Maria Maior|    225|                 4.5|           4|     1.0|  58.0|\n",
      "|  29396| 126415|Entire home/apt|Santa Maria Maior|    132|                 5.0|           4|     1.0|  67.0|\n",
      "|  29720| 128075|Entire home/apt|          Estrela|     14|                 5.0|          16|     9.0|1154.0|\n",
      "|  29872| 128698|Entire home/apt|        Alcântara|     25|                 5.0|           2|     1.0|  75.0|\n",
      "|  29891| 128792|Entire home/apt|     Misericórdia|     28|                 5.0|           3|     1.0|  49.0|\n",
      "|  29915| 128890|Entire home/apt|   Avenidas Novas|     28|                 4.5|           3|     1.0|  58.0|\n",
      "|  33312| 144398|Entire home/apt|     Misericórdia|     24|                 4.5|           4|     1.0|  66.0|\n",
      "+-------+-------+---------------+-----------------+-------+--------------------+------------+--------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airbnbDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wuKan656U_hO",
    "outputId": "9274401f-2d2b-4b2d-e255-ffc9c2f69372"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|      room_type|\n",
      "+---------------+\n",
      "|    Shared room|\n",
      "|Entire home/apt|\n",
      "|   Private room|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airbnbDF.select(airbnbDF.room_type).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rCEnfd_9U_hP",
    "outputId": "e66c59e0-472a-4c5f-c6a0-581bc37fa878"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- room_id: integer (nullable = true)\n",
      " |-- host_id: integer (nullable = true)\n",
      " |-- room_type: string (nullable = true)\n",
      " |-- neighborhood: string (nullable = true)\n",
      " |-- reviews: integer (nullable = true)\n",
      " |-- overall_satisfaction: double (nullable = true)\n",
      " |-- accommodates: integer (nullable = true)\n",
      " |-- bedrooms: double (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airbnbDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nv4_PhK2U_hP",
    "outputId": "3c940aeb-71c1-4fb2-d816-428b53e91a80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- room_id: integer (nullable = true)\n",
      " |-- host_id: integer (nullable = true)\n",
      " |-- room_type: string (nullable = true)\n",
      " |-- neighborhood: string (nullable = true)\n",
      " |-- reviews: integer (nullable = true)\n",
      " |-- overall_satisfaction: double (nullable = true)\n",
      " |-- accommodates: integer (nullable = true)\n",
      " |-- bedrooms: double (nullable = true)\n",
      " |-- price: decimal(10,2) (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import DecimalType\n",
    "\n",
    "# Castear 'price' a DecimalType(10, 2)\n",
    "airbnbDF = airbnbDF.withColumn('price',airbnbDF.price.cast(DecimalType(10,2)))\n",
    "airbnbDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0AtdTOmU_hQ"
   },
   "source": [
    "En concreto el dataset tiene las siguientes variables:\n",
    "- room_id: el identificador de la propiedad\n",
    "- host_id: el identificador del dueño de la propiedad\n",
    "- room_type: tipo de propiedad (vivienda completa/(habitacion para compartir/habitación privada)\n",
    "- neighborhood: el barrio de Lisboa\n",
    "- reviews: El numero de opiniones\n",
    "- overall_satisfaction: Puntuacion media del apartamento\n",
    "- accommodates: El numero de personas que se pueden alojar en la propiedad\n",
    "- bedrooms: El número de habitaciones\n",
    "- price: El precio (en euros) por noche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bjJ0JXpU_hR"
   },
   "source": [
    "<h3>Generación de Vista <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3ifxhedjU_hR"
   },
   "outputs": [],
   "source": [
    "airbnbDF.createOrReplaceTempView('properties')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtjfI6DGU_hR"
   },
   "source": [
    "## Usando SQL y Pyspark.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ST3rWZLwU_hS"
   },
   "source": [
    "### Caso 1.\n",
    "\n",
    "Alicia va a ir a Lisboa durante una semana con su marido y sus 2 hijos. Están buscando un apartamento con habitaciones separadas para los padres y los hijos. No les importa donde alojarse o el precio, simplemente quieren tener una experiencia agradable. Esto significa que solo aceptan lugares con más de 10 críticas con una puntuación mayor de 4. Cuando seleccionemos habitaciones para Alicia, tenemos que asegurarnos de ordenar las habitaciones de mejor a peor puntuación. Para aquellas habitaciones que tienen la misma puntuación, debemos mostrar antes aquellas con más críticas. Debemos darle 3 alternativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "3UtxTE2nU_hS",
    "outputId": "417cd956-ff96-4e33-89d2-6f7f1ace6265"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------+-----------------+-------+--------------------+------------+--------+-----+\n",
      "|room_id|host_id|   room_type|     neighborhood|reviews|overall_satisfaction|accommodates|bedrooms|price|\n",
      "+-------+-------+------------+-----------------+-------+--------------------+------------+--------+-----+\n",
      "| 876537|4544870|Private room|    Santo António|    253|                 5.0|           2|     1.0|31.00|\n",
      "|1113994|6108352|Private room|Santa Maria Maior|    225|                 5.0|           2|     1.0|46.00|\n",
      "|  90387| 490050|Private room|    Santo António|    204|                 5.0|           2|     1.0|46.00|\n",
      "+-------+-------+------------+-----------------+-------+--------------------+------------+--------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT * FROM properties \n",
    "        WHERE room_type = \"Private room\" AND \n",
    "        reviews > 10 AND \n",
    "        overall_satisfaction > 4.0\n",
    "        ORDER BY overall_satisfaction DESC, reviews DESC;\n",
    "        \"\"\"\n",
    "# ORDER BY reviews ASC,overall_satisfaction ASC;\n",
    "case1DF = spark.sql(query)\n",
    "case1DF.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "STrtfpuNU_hS",
    "outputId": "8fa0f9d3-5f87-46f9-bc69-9d25c3c4dbdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------+-----------------+-------+--------------------+------------+--------+-----+\n",
      "|room_id|host_id|   room_type|     neighborhood|reviews|overall_satisfaction|accommodates|bedrooms|price|\n",
      "+-------+-------+------------+-----------------+-------+--------------------+------------+--------+-----+\n",
      "| 876537|4544870|Private room|    Santo António|    253|                 5.0|           2|     1.0|31.00|\n",
      "|1113994|6108352|Private room|Santa Maria Maior|    225|                 5.0|           2|     1.0|46.00|\n",
      "|  90387| 490050|Private room|    Santo António|    204|                 5.0|           2|     1.0|46.00|\n",
      "+-------+-------+------------+-----------------+-------+--------------------+------------+--------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cond =  (airbnbDF.room_type == \"Private room\") & (airbnbDF.reviews > 10) & (airbnbDF.overall_satisfaction > 4.0)\n",
    "airbnbDF.select(\"*\").where(cond).orderBy(airbnbDF.overall_satisfaction.desc(),airbnbDF.reviews.desc()).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_a4paoWU_hT"
   },
   "source": [
    "### Caso 2\n",
    "\n",
    "Roberto es un casero que tiene una casa en Airbnb. De vez en cuando nos llama preguntando sobre cuales son las críticas de su alojamiento. Hoy está particularmente enfadado, ya que su hermana Clara ha puesto una casa en Airbnb y Roberto quiere asegurarse de que su casa tiene más críticas que las de Clara. Tenemos que crear un dataframe con las propiedades de ambos. Las id de las casas de Roberto y Clara son 97503 y 90387  respectivamente. Finalmente guardamos este dataframe como excel llamado \"roberto.xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "d3UlT6wbU_hT",
    "outputId": "654dcd25-bac2-49fe-9dd7-1169908eeeff",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------+-------------+-------+--------------------+------------+--------+-----+\n",
      "|room_id|host_id|   room_type| neighborhood|reviews|overall_satisfaction|accommodates|bedrooms|price|\n",
      "+-------+-------+------------+-------------+-------+--------------------+------------+--------+-----+\n",
      "|  90387| 490050|Private room|Santo António|    204|                 5.0|           2|     1.0|46.00|\n",
      "|  97503| 515924|Private room|Santo António|     39|                 4.0|           2|     1.0|26.00|\n",
      "+-------+-------+------------+-------------+-------+--------------------+------------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT * FROM properties \n",
    "        WHERE room_id IN (97503,90387)\n",
    "        \"\"\"\n",
    "case2DF = spark.sql(query)\n",
    "case2DF.show()\n",
    "\n",
    "# Escritura\n",
    "path_out = 'data/exercises/compareRobertoClara'\n",
    "\n",
    "options = {\n",
    "    'header': True,\n",
    "#     'sep': ','\n",
    "    'delimiter':','\n",
    "}\n",
    "\n",
    "# Write as CSV\n",
    "(\n",
    "case2DF.write\n",
    " .format(\"csv\")\n",
    " .mode(\"overwrite\")\n",
    " .option(\"sep\",\"\\t\")\n",
    " .save(path_out)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "J8CFg7SKjdTF",
    "outputId": "694db4b2-b5c0-48bf-c0f2-364c69d905c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------+-------------+-------+--------------------+------------+--------+-----+\n",
      "|room_id|host_id|   room_type| neighborhood|reviews|overall_satisfaction|accommodates|bedrooms|price|\n",
      "+-------+-------+------------+-------------+-------+--------------------+------------+--------+-----+\n",
      "|  90387| 490050|Private room|Santo António|    204|                 5.0|           2|     1.0|46.00|\n",
      "|  97503| 515924|Private room|Santo António|     39|                 4.0|           2|     1.0|26.00|\n",
      "+-------+-------+------------+-------------+-------+--------------------+------------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cond =  (airbnbDF.room_id.isin(97503,90387))\n",
    "case2DF = airbnbDF.select(\"*\").where(cond)\n",
    "\n",
    "case2DF.show()\n",
    "\n",
    "# Write as CSV\n",
    "(\n",
    "case2DF.write\n",
    " .format(\"csv\")\n",
    " .mode(\"overwrite\")\n",
    " .option(\"sep\",\"\\t\")\n",
    " .save(path_out)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zybco6-2U_hU"
   },
   "source": [
    "\n",
    "### Caso 3\n",
    "\n",
    "Diana va a Lisboa a pasar 3 noches y quiere conocer a gente nueva. Tiene un presupuesto de 50€ para su alojamiento. Debemos buscarle las 10 propiedades más baratas, dandole preferencia a aquellas que sean habitaciones compartidas *(room_type == Shared room)*, y para aquellas viviendas compartidas debemos elegir aquellas con mejor puntuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "TPrVSKNvU_hU",
    "outputId": "6a484516-cb47-43fe-d93c-d4c43e87209d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-----------+--------------+-------+--------------------+------------+--------+-----+\n",
      "| room_id| host_id|  room_type|  neighborhood|reviews|overall_satisfaction|accommodates|bedrooms|price|\n",
      "+--------+--------+-----------+--------------+-------+--------------------+------------+--------+-----+\n",
      "| 5803348|29676067|Shared room|  Misericórdia|     19|                 5.0|           9|     1.0| 20.0|\n",
      "|12826213| 6981742|Shared room|      Alvalade|     19|                 5.0|           1|     1.0| 22.0|\n",
      "| 7722107|40574313|Shared room|Avenidas Novas|     22|                 5.0|           4|     1.0| 36.0|\n",
      "| 5725814|29676067|Shared room|  Misericórdia|     23|                 5.0|           6|     1.0| 21.0|\n",
      "|10172929|52218341|Shared room|       Areeiro|     17|                 5.0|           1|     1.0| 20.0|\n",
      "|11523225|58899339|Shared room|Avenidas Novas|      4|                 5.0|           9|     1.0| 23.0|\n",
      "|12305540|66077974|Shared room|       Arroios|     40|                 5.0|           1|     1.0| 13.0|\n",
      "|12268067|66077974|Shared room|       Arroios|     96|                 5.0|           1|     1.0| 16.0|\n",
      "|10397682|32344156|Shared room|  Misericórdia|     15|                 5.0|           8|     1.0| 13.0|\n",
      "|12299998|66077974|Shared room|       Arroios|     49|                 5.0|           1|     1.0| 13.0|\n",
      "+--------+--------+-----------+--------------+-------+--------------------+------------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT * FROM properties \n",
    "        WHERE price <= 50.0 AND \n",
    "        room_type == \"Shared room\"\n",
    "        ORDER BY overall_satisfaction DESC;\n",
    "        \"\"\"\n",
    "case2DF = spark.sql(query)\n",
    "case2DF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ylH-OuuRnPED",
    "outputId": "ed6a02f6-0891-4af6-c1c9-20874e85f814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-----------+--------------+-------+--------------------+------------+--------+-----+\n",
      "| room_id| host_id|  room_type|  neighborhood|reviews|overall_satisfaction|accommodates|bedrooms|price|\n",
      "+--------+--------+-----------+--------------+-------+--------------------+------------+--------+-----+\n",
      "| 5803348|29676067|Shared room|  Misericórdia|     19|                 5.0|           9|     1.0| 20.0|\n",
      "|12826213| 6981742|Shared room|      Alvalade|     19|                 5.0|           1|     1.0| 22.0|\n",
      "| 7722107|40574313|Shared room|Avenidas Novas|     22|                 5.0|           4|     1.0| 36.0|\n",
      "| 5725814|29676067|Shared room|  Misericórdia|     23|                 5.0|           6|     1.0| 21.0|\n",
      "|10172929|52218341|Shared room|       Areeiro|     17|                 5.0|           1|     1.0| 20.0|\n",
      "|11523225|58899339|Shared room|Avenidas Novas|      4|                 5.0|           9|     1.0| 23.0|\n",
      "|12305540|66077974|Shared room|       Arroios|     40|                 5.0|           1|     1.0| 13.0|\n",
      "|12268067|66077974|Shared room|       Arroios|     96|                 5.0|           1|     1.0| 16.0|\n",
      "|10397682|32344156|Shared room|  Misericórdia|     15|                 5.0|           8|     1.0| 13.0|\n",
      "|12299998|66077974|Shared room|       Arroios|     49|                 5.0|           1|     1.0| 13.0|\n",
      "+--------+--------+-----------+--------------+-------+--------------------+------------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cond =  (airbnbDF.price <= 50) & (airbnbDF.room_type == \"Shared room\")\n",
    "case3DF = airbnbDF.select(\"*\").where(cond).orderBy(airbnbDF.overall_satisfaction.desc())\n",
    "\n",
    "case2DF.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Error en Local Window Spark 3.1.2 Haddop 3.2 Python 3.8.1 </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o49.save.\n: org.apache.spark.SparkException: Job aborted.\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:231)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:188)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)\r\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z\r\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)\r\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)\r\n\tat org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)\r\n\tat org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:332)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:402)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:375)\r\n\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:182)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:220)\r\n\t... 32 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d82d0e5bfa25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Write as CSV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m (\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mcase2DF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m  \u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m  \u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"overwrite\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigData\\lib\\site-packages\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0msince\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigData\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigData\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bigData\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 raise Py4JJavaError(\n\u001b[0m\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o49.save.\n: org.apache.spark.SparkException: Job aborted.\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:231)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:188)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)\r\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z\r\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)\r\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)\r\n\tat org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)\r\n\tat org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:332)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:402)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:375)\r\n\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:182)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:220)\r\n\t... 32 more\r\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT * FROM properties \n",
    "        WHERE room_id IN (97503,90387)\n",
    "        \"\"\"\n",
    "case2DF = spark.sql(query)\n",
    "# case2DF.show()\n",
    "\n",
    "# Escritura\n",
    "path_out = 'data/exercises/compareRobertoClara'\n",
    "\n",
    "options = {\n",
    "    'header': True,\n",
    "#     'sep': ','\n",
    "    'delimiter':','\n",
    "}\n",
    "\n",
    "# Write as CSV\n",
    "(\n",
    "case2DF.write\n",
    " .format(\"csv\")\n",
    " .mode(\"overwrite\")\n",
    " .option(\"sep\",\"\\t\")\n",
    " .save(path_out)\n",
    ")\n",
    "    \n",
    "# Export as XLS\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "2. Filtrado de DataFrames y Series - ejercicio.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
